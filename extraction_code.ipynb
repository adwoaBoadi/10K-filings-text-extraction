{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sec_api import ExtractorApi, QueryApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling in the API key. This key is generated from the sec-api.oi website.\n",
    "The API_KEY is a string that serves as an authentication token, granting the user access to the API's services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'your own API key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifiy the location of your file and the desitation of text extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = './data.xlsx'\n",
    "\n",
    "OUTPUT_FOLDER = '/output_folder/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExtractorApi is designed to extract specific information from SEC filings, such as 10-Ks.\n",
    "\n",
    "QueryApi is used to perform queries or searches in the SEC database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the API classes\n",
    "extractorApi = ExtractorApi(API_KEY)\n",
    "queryApi = QueryApi(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data file into a dataframe and saving the list of tickers of firms of interest to used in a for loop for text extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(DATA_FILE)\n",
    "\n",
    "list_of_tickers = list(df['ticker_symbol'].dropna().astype('str'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Precompile the regular expression\n",
    "clean_pattern = re.compile(r\"\\n|&#[0-9]+;\")\n",
    "\n",
    "# Process the tickers\n",
    "for ticker in list_of_tickers:\n",
    "    query = {\n",
    "        \"query\": {\"query_string\": {\n",
    "            \"query\": f\"formType:\\\"10-K\\\" AND ticker:\\\"{ticker}\\\"\",\n",
    "        }},\n",
    "        \"from\": \"0\",\n",
    "        \"sort\": [{\"filedAt\": {\"order\": \"desc\"}}]\n",
    "    }\n",
    "    \n",
    "    response = queryApi.get_filings(query)\n",
    "    filings = response.get('filings', [])\n",
    "    \n",
    "    if not filings:\n",
    "        continue\n",
    "    \n",
    "    # Initialize an empty string to store all concatenated texts\n",
    "    concatenated_texts = \"\"\n",
    "    \n",
    "    # Extract the sections for each filing\n",
    "    for filing in filings:\n",
    "        for item in ['1', '7', '9', '9A', '9B']:\n",
    "            try:\n",
    "                section_text = extractorApi.get_section(filing['linkToFilingDetails'], item, 'text')\n",
    "                concatenated_texts += section_text\n",
    "            except Exception as e:\n",
    "                continue  # Handle other actions or logging\n",
    "    \n",
    "    # Clean the concatenated text\n",
    "    cleaned_text = clean_pattern.sub(\"\", concatenated_texts)\n",
    "    \n",
    "    # Write the cleaned text to a file\n",
    "    file_path = f\"{OUTPUT_FOLDER}{ticker}.txt\"\n",
    "    with open(file_path, 'w') as output_file:\n",
    "        output_file.write(cleaned_text)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
